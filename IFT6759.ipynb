{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vijayakuruba/IFT6759_Distribution_shifts_WILDS/blob/main/IFT6759.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mount drive"
      ],
      "metadata": {
        "id": "8E-KYxSObiOK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIe1yICxX0cr",
        "outputId": "b8bf269b-f068-45d4-f83e-5200d4a4deb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone the git"
      ],
      "metadata": {
        "id": "a4CGeo2ScHzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "DHPQOJESkdIW",
        "outputId": "4fef3e55-7ebb-4b32-ccf5-5d3e04b7b866",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/vijayakuruba/IFT6759_Distribution_shifts_WILDS.git"
      ],
      "metadata": {
        "id": "5vCtFBT2btb8",
        "outputId": "3994c1d9-2b1c-4fb5-dd95-493dee95483a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IFT6759_Distribution_shifts_WILDS'...\n",
            "remote: Enumerating objects: 110, done.\u001b[K\n",
            "remote: Counting objects: 100% (110/110), done.\u001b[K\n",
            "remote: Compressing objects: 100% (104/104), done.\u001b[K\n",
            "remote: Total 110 (delta 12), reused 93 (delta 3), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (110/110), 124.52 KiB | 3.37 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwtLkFSrYXxw",
        "outputId": "242dab9c-3929-4085-9fa1-8e9e68afae81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/IFT6759_Distribution_shifts_WILDS\n",
            "dataset_preprocessing  gitignore      README.md  wilds\n",
            "examples\t       IFT6759.ipynb  setup.py\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/My Drive/IFT6759_Distribution_shifts_WILDS/\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install requirements"
      ],
      "metadata": {
        "id": "GEks6_sjcfF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wilds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ize2FIfN05To",
        "outputId": "6a83cc69-25f8-4a22-f056-5e52ceb2a64d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wilds\n",
            "  Downloading wilds-2.0.0-py3-none-any.whl (126 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 25.2 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20 kB 27.1 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 81 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 126 kB 9.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.1 in /usr/local/lib/python3.7/dist-packages (from wilds) (1.21.5)\n",
            "Collecting scipy>=1.5.4\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from wilds) (1.10.0+cu111)\n",
            "Collecting pillow>=7.2.0\n",
            "  Downloading Pillow-9.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 46.9 MB/s \n",
            "\u001b[?25hCollecting pytz>=2020.4\n",
            "  Downloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 43.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from wilds) (1.3.5)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from wilds) (0.11.1+cu111)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from wilds) (1.0.2)\n",
            "Collecting ogb>=1.2.6\n",
            "  Downloading ogb-1.3.3-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.6 MB/s \n",
            "\u001b[?25hCollecting outdated>=0.2.0\n",
            "  Downloading outdated-0.2.1-py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: tqdm>=4.53.0 in /usr/local/lib/python3.7/dist-packages (from wilds) (4.63.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb>=1.2.6->wilds) (1.24.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from ogb>=1.2.6->wilds) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->wilds) (2.23.0)\n",
            "Collecting littleutils\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->wilds) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->wilds) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->wilds) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->wilds) (3.10.0.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->wilds) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->wilds) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->wilds) (2021.10.8)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=fa7fd8bc61ca8ac63e6b00d418d970050bb6200ea259bde335dc74075845756b\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/64/cd/32819b511a488e4993f2fab909a95330289c3f4e0f6ef4676d\n",
            "Successfully built littleutils\n",
            "Installing collected packages: scipy, pytz, littleutils, pillow, outdated, ogb, wilds\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed littleutils-0.2.2 ogb-1.3.3 outdated-0.2.1 pillow-9.0.1 pytz-2021.3 scipy-1.7.3 wilds-2.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yQEeek_beOO",
        "outputId": "d17b170c-677d-44a5-bbbf-6c7c1c0f3c54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.0.9.tar.gz (21 kB)\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl size=3874184 sha256=d1b73dbb576725f308f0c74331855ab249bb9c9d2a65c8d1989d7c3476e6c3ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/57/a3/42ea193b77378ce634eb9454c9bc1e3163f3b482a35cdee4d1\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.3.tar.gz (370 kB)\n",
            "\u001b[K     |████████████████████████████████| 370 kB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.63.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-6.1.1-py3-none-any.whl (482 kB)\n",
            "\u001b[K     |████████████████████████████████| 482 kB 32.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.7)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2021.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (4.11.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 673 kB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.10.0.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.3-py3-none-any.whl size=581968 sha256=356512ace6868a0b13e28797bc3851f8161beaa13f331411cf23b336a3944f4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/c3/2a/58/87ce0508964d4def1aafb92750c4f3ac77038efd1b9a89dcf5\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, yacs, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.1 rdflib-6.1.1 torch-geometric-2.0.3 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-scatter\n",
        "!pip install torch-geometric\n",
        "!pip install transformers>=3.5.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Use this If you want to download dataset seperately"
      ],
      "metadata": {
        "id": "Z8pkybsae_LQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Khcj-d4cohjq",
        "outputId": "89194647-ba80-4b80-a920-5c223b4b0a9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/IFT6759/clean/IFT6759_Distribution_shifts_WILDS/wilds\n",
            "common\t  download_datasets.py\t__init__.py  version.py\n",
            "datasets  get_dataset.py\t__pycache__\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/My Drive/IFT6759/clean/IFT6759_Distribution_shifts_WILDS/wilds\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python download_datasets.py --root_dir data"
      ],
      "metadata": {
        "id": "ytNJpX-VzmjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run experiments"
      ],
      "metadata": {
        "id": "nTmJ5p3yfMer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/IFT6759_Distribution_shifts_WILDS/examples\n",
        "!ls"
      ],
      "metadata": {
        "id": "xXv0aJQRMaU0",
        "outputId": "aec0537e-78a5-43ea-d244-40872d959eef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/IFT6759_Distribution_shifts_WILDS/examples\n",
            "algorithms\t   evaluate.py\tmodels\t      run_expt.py   transforms.py\n",
            "configs\t\t   __init__.py\toptimizer.py  scheduler.py  utils.py\n",
            "data_augmentation  losses.py\t__pycache__   train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fhJoEAMEgiFX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "136ea965-f5b3-43a1-badd-88fdb84aeb3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "objective: 0.060\n",
            "loss_avg: 0.060\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.092\n",
            "loss_avg: 0.092\n",
            "acc_avg: 0.978\n",
            "\n",
            "objective: 0.063\n",
            "loss_avg: 0.063\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.072\n",
            "loss_avg: 0.072\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.107\n",
            "loss_avg: 0.107\n",
            "acc_avg: 0.977\n",
            "\n",
            "objective: 0.086\n",
            "loss_avg: 0.086\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.061\n",
            "loss_avg: 0.061\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.083\n",
            "loss_avg: 0.083\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.063\n",
            "loss_avg: 0.063\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.071\n",
            "loss_avg: 0.071\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.054\n",
            "loss_avg: 0.054\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.070\n",
            "loss_avg: 0.070\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.042\n",
            "loss_avg: 0.042\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.061\n",
            "loss_avg: 0.061\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.074\n",
            "loss_avg: 0.074\n",
            "acc_avg: 0.976\n",
            "\n",
            "objective: 0.067\n",
            "loss_avg: 0.067\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.073\n",
            "loss_avg: 0.073\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.100\n",
            "loss_avg: 0.100\n",
            "acc_avg: 0.976\n",
            "\n",
            "objective: 0.097\n",
            "loss_avg: 0.097\n",
            "acc_avg: 0.965\n",
            "\n",
            "objective: 0.062\n",
            "loss_avg: 0.062\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.085\n",
            "loss_avg: 0.085\n",
            "acc_avg: 0.976\n",
            "\n",
            "objective: 0.077\n",
            "loss_avg: 0.077\n",
            "acc_avg: 0.975\n",
            "\n",
            "objective: 0.115\n",
            "loss_avg: 0.115\n",
            "acc_avg: 0.972\n",
            "\n",
            "objective: 0.083\n",
            "loss_avg: 0.083\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.066\n",
            "loss_avg: 0.066\n",
            "acc_avg: 0.978\n",
            "\n",
            "objective: 0.068\n",
            "loss_avg: 0.068\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.069\n",
            "loss_avg: 0.069\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.082\n",
            "loss_avg: 0.082\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.074\n",
            "loss_avg: 0.074\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.053\n",
            "loss_avg: 0.053\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.070\n",
            "loss_avg: 0.070\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.049\n",
            "loss_avg: 0.049\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.082\n",
            "loss_avg: 0.082\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.066\n",
            "loss_avg: 0.066\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.066\n",
            "loss_avg: 0.066\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.046\n",
            "loss_avg: 0.046\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.042\n",
            "loss_avg: 0.042\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.072\n",
            "loss_avg: 0.072\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.074\n",
            "loss_avg: 0.074\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.085\n",
            "loss_avg: 0.085\n",
            "acc_avg: 0.976\n",
            "\n",
            "objective: 0.059\n",
            "loss_avg: 0.059\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.065\n",
            "loss_avg: 0.065\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.047\n",
            "loss_avg: 0.047\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.046\n",
            "loss_avg: 0.046\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.068\n",
            "loss_avg: 0.068\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.062\n",
            "loss_avg: 0.062\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.077\n",
            "loss_avg: 0.077\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.088\n",
            "loss_avg: 0.088\n",
            "acc_avg: 0.976\n",
            "\n",
            "Epoch eval:\n",
            "Average acc: 0.982\n",
            "Recall macro: 0.594\n",
            "F1 macro: 0.616\n",
            "\n",
            "Validation (OOD/Trans):\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "objective: 1.767\n",
            "loss_avg: 1.767\n",
            "acc_avg: 0.618\n",
            "\n",
            "Epoch eval:\n",
            "Average acc: 0.618\n",
            "Recall macro: 0.383\n",
            "F1 macro: 0.344\n",
            "Validation F1-macro_all: 0.344\n",
            "Epoch 4 has the best validation performance so far.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\n",
            "Epoch [5]:\n",
            "\n",
            "Train:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "objective: 0.063\n",
            "loss_avg: 0.063\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.054\n",
            "loss_avg: 0.054\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.055\n",
            "loss_avg: 0.055\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.050\n",
            "loss_avg: 0.050\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.051\n",
            "loss_avg: 0.051\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.067\n",
            "loss_avg: 0.067\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.043\n",
            "loss_avg: 0.043\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.030\n",
            "loss_avg: 0.030\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.060\n",
            "loss_avg: 0.060\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.057\n",
            "loss_avg: 0.057\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.050\n",
            "loss_avg: 0.050\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.050\n",
            "loss_avg: 0.050\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.058\n",
            "loss_avg: 0.058\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.049\n",
            "loss_avg: 0.049\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.047\n",
            "loss_avg: 0.047\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.055\n",
            "loss_avg: 0.055\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.053\n",
            "loss_avg: 0.053\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.062\n",
            "loss_avg: 0.062\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.054\n",
            "loss_avg: 0.054\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.073\n",
            "loss_avg: 0.073\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.055\n",
            "loss_avg: 0.055\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.048\n",
            "loss_avg: 0.048\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.048\n",
            "loss_avg: 0.048\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.051\n",
            "loss_avg: 0.051\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.078\n",
            "loss_avg: 0.078\n",
            "acc_avg: 0.978\n",
            "\n",
            "objective: 0.066\n",
            "loss_avg: 0.066\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.051\n",
            "loss_avg: 0.051\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.052\n",
            "loss_avg: 0.052\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.046\n",
            "loss_avg: 0.046\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.047\n",
            "loss_avg: 0.047\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.046\n",
            "loss_avg: 0.046\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.062\n",
            "loss_avg: 0.062\n",
            "acc_avg: 0.982\n",
            "\n",
            "objective: 0.054\n",
            "loss_avg: 0.054\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.058\n",
            "loss_avg: 0.058\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.089\n",
            "loss_avg: 0.089\n",
            "acc_avg: 0.972\n",
            "\n",
            "objective: 0.070\n",
            "loss_avg: 0.070\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.050\n",
            "loss_avg: 0.050\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.065\n",
            "loss_avg: 0.065\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.061\n",
            "loss_avg: 0.061\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.063\n",
            "loss_avg: 0.063\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.046\n",
            "loss_avg: 0.046\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.043\n",
            "loss_avg: 0.043\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.051\n",
            "loss_avg: 0.051\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.063\n",
            "loss_avg: 0.063\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.060\n",
            "loss_avg: 0.060\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.078\n",
            "loss_avg: 0.078\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.048\n",
            "loss_avg: 0.048\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.059\n",
            "loss_avg: 0.059\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.067\n",
            "loss_avg: 0.067\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.055\n",
            "loss_avg: 0.055\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.052\n",
            "loss_avg: 0.052\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.059\n",
            "loss_avg: 0.059\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.061\n",
            "loss_avg: 0.061\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.061\n",
            "loss_avg: 0.061\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.066\n",
            "loss_avg: 0.066\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.055\n",
            "loss_avg: 0.055\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.073\n",
            "loss_avg: 0.073\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.056\n",
            "loss_avg: 0.056\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.119\n",
            "loss_avg: 0.119\n",
            "acc_avg: 0.970\n",
            "\n",
            "objective: 0.093\n",
            "loss_avg: 0.093\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.052\n",
            "loss_avg: 0.052\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.046\n",
            "loss_avg: 0.046\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.061\n",
            "loss_avg: 0.061\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.058\n",
            "loss_avg: 0.058\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.045\n",
            "loss_avg: 0.045\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.051\n",
            "loss_avg: 0.051\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.055\n",
            "loss_avg: 0.055\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.057\n",
            "loss_avg: 0.057\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.081\n",
            "loss_avg: 0.081\n",
            "acc_avg: 0.978\n",
            "\n",
            "objective: 0.049\n",
            "loss_avg: 0.049\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.062\n",
            "loss_avg: 0.062\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.052\n",
            "loss_avg: 0.052\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.066\n",
            "loss_avg: 0.066\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.051\n",
            "loss_avg: 0.051\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.059\n",
            "loss_avg: 0.059\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.095\n",
            "loss_avg: 0.095\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.093\n",
            "loss_avg: 0.093\n",
            "acc_avg: 0.973\n",
            "\n",
            "objective: 0.051\n",
            "loss_avg: 0.051\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.057\n",
            "loss_avg: 0.057\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.066\n",
            "loss_avg: 0.066\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.090\n",
            "loss_avg: 0.090\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.063\n",
            "loss_avg: 0.063\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.067\n",
            "loss_avg: 0.067\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.067\n",
            "loss_avg: 0.067\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.075\n",
            "loss_avg: 0.075\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.069\n",
            "loss_avg: 0.069\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.048\n",
            "loss_avg: 0.048\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.046\n",
            "loss_avg: 0.046\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.064\n",
            "loss_avg: 0.064\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.073\n",
            "loss_avg: 0.073\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.068\n",
            "loss_avg: 0.068\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.046\n",
            "loss_avg: 0.046\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.067\n",
            "loss_avg: 0.067\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.050\n",
            "loss_avg: 0.050\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.055\n",
            "loss_avg: 0.055\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.052\n",
            "loss_avg: 0.052\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.050\n",
            "loss_avg: 0.050\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.057\n",
            "loss_avg: 0.057\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.073\n",
            "loss_avg: 0.073\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.065\n",
            "loss_avg: 0.065\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.051\n",
            "loss_avg: 0.051\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.046\n",
            "loss_avg: 0.046\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.082\n",
            "loss_avg: 0.082\n",
            "acc_avg: 0.976\n",
            "\n",
            "objective: 0.085\n",
            "loss_avg: 0.085\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.049\n",
            "loss_avg: 0.049\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.050\n",
            "loss_avg: 0.050\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.046\n",
            "loss_avg: 0.046\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.052\n",
            "loss_avg: 0.052\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.060\n",
            "loss_avg: 0.060\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.071\n",
            "loss_avg: 0.071\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.055\n",
            "loss_avg: 0.055\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.066\n",
            "loss_avg: 0.066\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.046\n",
            "loss_avg: 0.046\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.055\n",
            "loss_avg: 0.055\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.072\n",
            "loss_avg: 0.072\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.070\n",
            "loss_avg: 0.070\n",
            "acc_avg: 0.978\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.048\n",
            "loss_avg: 0.048\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.064\n",
            "loss_avg: 0.064\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.065\n",
            "loss_avg: 0.065\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.075\n",
            "loss_avg: 0.075\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.058\n",
            "loss_avg: 0.058\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.059\n",
            "loss_avg: 0.059\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.060\n",
            "loss_avg: 0.060\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.049\n",
            "loss_avg: 0.049\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.067\n",
            "loss_avg: 0.067\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.097\n",
            "loss_avg: 0.097\n",
            "acc_avg: 0.976\n",
            "\n",
            "objective: 0.073\n",
            "loss_avg: 0.073\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.062\n",
            "loss_avg: 0.062\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.047\n",
            "loss_avg: 0.047\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.045\n",
            "loss_avg: 0.045\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.077\n",
            "loss_avg: 0.077\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.107\n",
            "loss_avg: 0.107\n",
            "acc_avg: 0.976\n",
            "\n",
            "objective: 0.073\n",
            "loss_avg: 0.073\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.054\n",
            "loss_avg: 0.054\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.047\n",
            "loss_avg: 0.047\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.042\n",
            "loss_avg: 0.042\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.053\n",
            "loss_avg: 0.053\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.064\n",
            "loss_avg: 0.064\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.063\n",
            "loss_avg: 0.063\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.990\n",
            "\n",
            "Epoch eval:\n",
            "Average acc: 0.985\n",
            "Recall macro: 0.636\n",
            "F1 macro: 0.659\n",
            "\n",
            "Validation (OOD/Trans):\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "objective: 1.679\n",
            "loss_avg: 1.679\n",
            "acc_avg: 0.644\n",
            "\n",
            "Epoch eval:\n",
            "Average acc: 0.644\n",
            "Recall macro: 0.384\n",
            "F1 macro: 0.369\n",
            "Validation F1-macro_all: 0.369\n",
            "Epoch 5 has the best validation performance so far.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\n",
            "Epoch [6]:\n",
            "\n",
            "Train:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.042\n",
            "loss_avg: 0.042\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.023\n",
            "loss_avg: 0.023\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.024\n",
            "loss_avg: 0.024\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.047\n",
            "loss_avg: 0.047\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.019\n",
            "loss_avg: 0.019\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.042\n",
            "loss_avg: 0.042\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.059\n",
            "loss_avg: 0.059\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.059\n",
            "loss_avg: 0.059\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.025\n",
            "loss_avg: 0.025\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.043\n",
            "loss_avg: 0.043\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.023\n",
            "loss_avg: 0.023\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.053\n",
            "loss_avg: 0.053\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.081\n",
            "loss_avg: 0.081\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.075\n",
            "loss_avg: 0.075\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.069\n",
            "loss_avg: 0.069\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.067\n",
            "loss_avg: 0.067\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.051\n",
            "loss_avg: 0.051\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.062\n",
            "loss_avg: 0.062\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.055\n",
            "loss_avg: 0.055\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.054\n",
            "loss_avg: 0.054\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.046\n",
            "loss_avg: 0.046\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.054\n",
            "loss_avg: 0.054\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.049\n",
            "loss_avg: 0.049\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.058\n",
            "loss_avg: 0.058\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.063\n",
            "loss_avg: 0.063\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.049\n",
            "loss_avg: 0.049\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.052\n",
            "loss_avg: 0.052\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.047\n",
            "loss_avg: 0.047\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.023\n",
            "loss_avg: 0.023\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.051\n",
            "loss_avg: 0.051\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.039\n",
            "loss_avg: 0.039\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.046\n",
            "loss_avg: 0.046\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.050\n",
            "loss_avg: 0.050\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.074\n",
            "loss_avg: 0.074\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.056\n",
            "loss_avg: 0.056\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.052\n",
            "loss_avg: 0.052\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.058\n",
            "loss_avg: 0.058\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.030\n",
            "loss_avg: 0.030\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.066\n",
            "loss_avg: 0.066\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.056\n",
            "loss_avg: 0.056\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.069\n",
            "loss_avg: 0.069\n",
            "acc_avg: 0.976\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.064\n",
            "loss_avg: 0.064\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.049\n",
            "loss_avg: 0.049\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.043\n",
            "loss_avg: 0.043\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.048\n",
            "loss_avg: 0.048\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.061\n",
            "loss_avg: 0.061\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.043\n",
            "loss_avg: 0.043\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.050\n",
            "loss_avg: 0.050\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.060\n",
            "loss_avg: 0.060\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.066\n",
            "loss_avg: 0.066\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.051\n",
            "loss_avg: 0.051\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.043\n",
            "loss_avg: 0.043\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.050\n",
            "loss_avg: 0.050\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.069\n",
            "loss_avg: 0.069\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.042\n",
            "loss_avg: 0.042\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.058\n",
            "loss_avg: 0.058\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.053\n",
            "loss_avg: 0.053\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.050\n",
            "loss_avg: 0.050\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.059\n",
            "loss_avg: 0.059\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.053\n",
            "loss_avg: 0.053\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.051\n",
            "loss_avg: 0.051\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.045\n",
            "loss_avg: 0.045\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.046\n",
            "loss_avg: 0.046\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.043\n",
            "loss_avg: 0.043\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.066\n",
            "loss_avg: 0.066\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.055\n",
            "loss_avg: 0.055\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.042\n",
            "loss_avg: 0.042\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.039\n",
            "loss_avg: 0.039\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.059\n",
            "loss_avg: 0.059\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.062\n",
            "loss_avg: 0.062\n",
            "acc_avg: 0.977\n",
            "\n",
            "objective: 0.047\n",
            "loss_avg: 0.047\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.055\n",
            "loss_avg: 0.055\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.042\n",
            "loss_avg: 0.042\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.071\n",
            "loss_avg: 0.071\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.053\n",
            "loss_avg: 0.053\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.047\n",
            "loss_avg: 0.047\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.046\n",
            "loss_avg: 0.046\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.050\n",
            "loss_avg: 0.050\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.058\n",
            "loss_avg: 0.058\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.066\n",
            "loss_avg: 0.066\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.065\n",
            "loss_avg: 0.065\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.043\n",
            "loss_avg: 0.043\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.060\n",
            "loss_avg: 0.060\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.062\n",
            "loss_avg: 0.062\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.065\n",
            "loss_avg: 0.065\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.052\n",
            "loss_avg: 0.052\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.055\n",
            "loss_avg: 0.055\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.060\n",
            "loss_avg: 0.060\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.039\n",
            "loss_avg: 0.039\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.050\n",
            "loss_avg: 0.050\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.052\n",
            "loss_avg: 0.052\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.066\n",
            "loss_avg: 0.066\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.045\n",
            "loss_avg: 0.045\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.059\n",
            "loss_avg: 0.059\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.059\n",
            "loss_avg: 0.059\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.025\n",
            "loss_avg: 0.025\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.050\n",
            "loss_avg: 0.050\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.054\n",
            "loss_avg: 0.054\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.068\n",
            "loss_avg: 0.068\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.045\n",
            "loss_avg: 0.045\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.020\n",
            "loss_avg: 0.020\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.026\n",
            "loss_avg: 0.026\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.020\n",
            "loss_avg: 0.020\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.030\n",
            "loss_avg: 0.030\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.060\n",
            "loss_avg: 0.060\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.062\n",
            "loss_avg: 0.062\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.046\n",
            "loss_avg: 0.046\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.064\n",
            "loss_avg: 0.064\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.056\n",
            "loss_avg: 0.056\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.050\n",
            "loss_avg: 0.050\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.053\n",
            "loss_avg: 0.053\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.070\n",
            "loss_avg: 0.070\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.047\n",
            "loss_avg: 0.047\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.111\n",
            "loss_avg: 0.111\n",
            "acc_avg: 0.967\n",
            "\n",
            "Epoch eval:\n",
            "Average acc: 0.987\n",
            "Recall macro: 0.688\n",
            "F1 macro: 0.704\n",
            "\n",
            "Validation (OOD/Trans):\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "objective: 1.800\n",
            "loss_avg: 1.800\n",
            "acc_avg: 0.618\n",
            "\n",
            "Epoch eval:\n",
            "Average acc: 0.618\n",
            "Recall macro: 0.376\n",
            "F1 macro: 0.359\n",
            "Validation F1-macro_all: 0.359\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\n",
            "Epoch [7]:\n",
            "\n",
            "Train:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "objective: 0.049\n",
            "loss_avg: 0.049\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.026\n",
            "loss_avg: 0.026\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.026\n",
            "loss_avg: 0.026\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.026\n",
            "loss_avg: 0.026\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.048\n",
            "loss_avg: 0.048\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.025\n",
            "loss_avg: 0.025\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.019\n",
            "loss_avg: 0.019\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.023\n",
            "loss_avg: 0.023\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.063\n",
            "loss_avg: 0.063\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.024\n",
            "loss_avg: 0.024\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.023\n",
            "loss_avg: 0.023\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.021\n",
            "loss_avg: 0.021\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.052\n",
            "loss_avg: 0.052\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.030\n",
            "loss_avg: 0.030\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.043\n",
            "loss_avg: 0.043\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.043\n",
            "loss_avg: 0.043\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.072\n",
            "loss_avg: 0.072\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.054\n",
            "loss_avg: 0.054\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.051\n",
            "loss_avg: 0.051\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.046\n",
            "loss_avg: 0.046\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.046\n",
            "loss_avg: 0.046\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.045\n",
            "loss_avg: 0.045\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.043\n",
            "loss_avg: 0.043\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.047\n",
            "loss_avg: 0.047\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.057\n",
            "loss_avg: 0.057\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.059\n",
            "loss_avg: 0.059\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.070\n",
            "loss_avg: 0.070\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.062\n",
            "loss_avg: 0.062\n",
            "acc_avg: 0.976\n",
            "\n",
            "objective: 0.067\n",
            "loss_avg: 0.067\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.068\n",
            "loss_avg: 0.068\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.052\n",
            "loss_avg: 0.052\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.047\n",
            "loss_avg: 0.047\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.026\n",
            "loss_avg: 0.026\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.057\n",
            "loss_avg: 0.057\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.046\n",
            "loss_avg: 0.046\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.052\n",
            "loss_avg: 0.052\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.062\n",
            "loss_avg: 0.062\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.067\n",
            "loss_avg: 0.067\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.061\n",
            "loss_avg: 0.061\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.049\n",
            "loss_avg: 0.049\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.045\n",
            "loss_avg: 0.045\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.051\n",
            "loss_avg: 0.051\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.051\n",
            "loss_avg: 0.051\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.045\n",
            "loss_avg: 0.045\n",
            "acc_avg: 0.982\n",
            "\n",
            "objective: 0.053\n",
            "loss_avg: 0.053\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.030\n",
            "loss_avg: 0.030\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.060\n",
            "loss_avg: 0.060\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.048\n",
            "loss_avg: 0.048\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.043\n",
            "loss_avg: 0.043\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.066\n",
            "loss_avg: 0.066\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.068\n",
            "loss_avg: 0.068\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.057\n",
            "loss_avg: 0.057\n",
            "acc_avg: 0.982\n",
            "\n",
            "objective: 0.043\n",
            "loss_avg: 0.043\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.048\n",
            "loss_avg: 0.048\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.045\n",
            "loss_avg: 0.045\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.056\n",
            "loss_avg: 0.056\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.070\n",
            "loss_avg: 0.070\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.043\n",
            "loss_avg: 0.043\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.057\n",
            "loss_avg: 0.057\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.045\n",
            "loss_avg: 0.045\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.042\n",
            "loss_avg: 0.042\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.053\n",
            "loss_avg: 0.053\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.082\n",
            "loss_avg: 0.082\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.058\n",
            "loss_avg: 0.058\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.046\n",
            "loss_avg: 0.046\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.039\n",
            "loss_avg: 0.039\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.054\n",
            "loss_avg: 0.054\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.063\n",
            "loss_avg: 0.063\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.067\n",
            "loss_avg: 0.067\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.053\n",
            "loss_avg: 0.053\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.026\n",
            "loss_avg: 0.026\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.030\n",
            "loss_avg: 0.030\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.047\n",
            "loss_avg: 0.047\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.051\n",
            "loss_avg: 0.051\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.050\n",
            "loss_avg: 0.050\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.058\n",
            "loss_avg: 0.058\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.058\n",
            "loss_avg: 0.058\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.047\n",
            "loss_avg: 0.047\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.055\n",
            "loss_avg: 0.055\n",
            "acc_avg: 0.982\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.060\n",
            "loss_avg: 0.060\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.039\n",
            "loss_avg: 0.039\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.045\n",
            "loss_avg: 0.045\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.021\n",
            "loss_avg: 0.021\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.048\n",
            "loss_avg: 0.048\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.020\n",
            "loss_avg: 0.020\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.043\n",
            "loss_avg: 0.043\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.045\n",
            "loss_avg: 0.045\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.060\n",
            "loss_avg: 0.060\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.052\n",
            "loss_avg: 0.052\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.046\n",
            "loss_avg: 0.046\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.061\n",
            "loss_avg: 0.061\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.056\n",
            "loss_avg: 0.056\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.060\n",
            "loss_avg: 0.060\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.023\n",
            "loss_avg: 0.023\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.042\n",
            "loss_avg: 0.042\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.039\n",
            "loss_avg: 0.039\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.084\n",
            "loss_avg: 0.084\n",
            "acc_avg: 0.981\n",
            "\n",
            "Epoch eval:\n",
            "Average acc: 0.988\n",
            "Recall macro: 0.724\n",
            "F1 macro: 0.743\n",
            "\n",
            "Validation (OOD/Trans):\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "objective: 1.918\n",
            "loss_avg: 1.918\n",
            "acc_avg: 0.602\n",
            "\n",
            "Epoch eval:\n",
            "Average acc: 0.602\n",
            "Recall macro: 0.384\n",
            "F1 macro: 0.358\n",
            "Validation F1-macro_all: 0.358\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\n",
            "Epoch [8]:\n",
            "\n",
            "Train:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.021\n",
            "loss_avg: 0.021\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.023\n",
            "loss_avg: 0.023\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.050\n",
            "loss_avg: 0.050\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.054\n",
            "loss_avg: 0.054\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.018\n",
            "loss_avg: 0.018\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.049\n",
            "loss_avg: 0.049\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.025\n",
            "loss_avg: 0.025\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.015\n",
            "loss_avg: 0.015\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.025\n",
            "loss_avg: 0.025\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.012\n",
            "loss_avg: 0.012\n",
            "acc_avg: 0.998\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.024\n",
            "loss_avg: 0.024\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.018\n",
            "loss_avg: 0.018\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.043\n",
            "loss_avg: 0.043\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.023\n",
            "loss_avg: 0.023\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.048\n",
            "loss_avg: 0.048\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.043\n",
            "loss_avg: 0.043\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.053\n",
            "loss_avg: 0.053\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.030\n",
            "loss_avg: 0.030\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.052\n",
            "loss_avg: 0.052\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.049\n",
            "loss_avg: 0.049\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.055\n",
            "loss_avg: 0.055\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.047\n",
            "loss_avg: 0.047\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.026\n",
            "loss_avg: 0.026\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.054\n",
            "loss_avg: 0.054\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.025\n",
            "loss_avg: 0.025\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.061\n",
            "loss_avg: 0.061\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.053\n",
            "loss_avg: 0.053\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.057\n",
            "loss_avg: 0.057\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.059\n",
            "loss_avg: 0.059\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.046\n",
            "loss_avg: 0.046\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.025\n",
            "loss_avg: 0.025\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.039\n",
            "loss_avg: 0.039\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.019\n",
            "loss_avg: 0.019\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.018\n",
            "loss_avg: 0.018\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.030\n",
            "loss_avg: 0.030\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.047\n",
            "loss_avg: 0.047\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.050\n",
            "loss_avg: 0.050\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.042\n",
            "loss_avg: 0.042\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.049\n",
            "loss_avg: 0.049\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.066\n",
            "loss_avg: 0.066\n",
            "acc_avg: 0.982\n",
            "\n",
            "objective: 0.025\n",
            "loss_avg: 0.025\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.015\n",
            "loss_avg: 0.015\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.071\n",
            "loss_avg: 0.071\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.048\n",
            "loss_avg: 0.048\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.069\n",
            "loss_avg: 0.069\n",
            "acc_avg: 0.976\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.081\n",
            "loss_avg: 0.081\n",
            "acc_avg: 0.974\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.023\n",
            "loss_avg: 0.023\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.045\n",
            "loss_avg: 0.045\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.072\n",
            "loss_avg: 0.072\n",
            "acc_avg: 0.982\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.059\n",
            "loss_avg: 0.059\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.053\n",
            "loss_avg: 0.053\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.057\n",
            "loss_avg: 0.057\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.048\n",
            "loss_avg: 0.048\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.055\n",
            "loss_avg: 0.055\n",
            "acc_avg: 0.982\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.050\n",
            "loss_avg: 0.050\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.021\n",
            "loss_avg: 0.021\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.051\n",
            "loss_avg: 0.051\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.020\n",
            "loss_avg: 0.020\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.059\n",
            "loss_avg: 0.059\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.039\n",
            "loss_avg: 0.039\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.048\n",
            "loss_avg: 0.048\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.023\n",
            "loss_avg: 0.023\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.024\n",
            "loss_avg: 0.024\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.030\n",
            "loss_avg: 0.030\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.075\n",
            "loss_avg: 0.075\n",
            "acc_avg: 0.976\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.050\n",
            "loss_avg: 0.050\n",
            "acc_avg: 0.982\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.026\n",
            "loss_avg: 0.026\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.043\n",
            "loss_avg: 0.043\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.056\n",
            "loss_avg: 0.056\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.051\n",
            "loss_avg: 0.051\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.051\n",
            "loss_avg: 0.051\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.053\n",
            "loss_avg: 0.053\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.042\n",
            "loss_avg: 0.042\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.043\n",
            "loss_avg: 0.043\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.039\n",
            "loss_avg: 0.039\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.049\n",
            "loss_avg: 0.049\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.039\n",
            "loss_avg: 0.039\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.042\n",
            "loss_avg: 0.042\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.023\n",
            "loss_avg: 0.023\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.065\n",
            "loss_avg: 0.065\n",
            "acc_avg: 0.990\n",
            "\n",
            "Epoch eval:\n",
            "Average acc: 0.989\n",
            "Recall macro: 0.756\n",
            "F1 macro: 0.773\n",
            "\n",
            "Validation (OOD/Trans):\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "objective: 1.802\n",
            "loss_avg: 1.802\n",
            "acc_avg: 0.637\n",
            "\n",
            "Epoch eval:\n",
            "Average acc: 0.637\n",
            "Recall macro: 0.370\n",
            "F1 macro: 0.351\n",
            "Validation F1-macro_all: 0.351\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\n",
            "Epoch [9]:\n",
            "\n",
            "Train:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.018\n",
            "loss_avg: 0.018\n",
            "acc_avg: 0.998\n",
            "\n",
            "objective: 0.026\n",
            "loss_avg: 0.026\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.026\n",
            "loss_avg: 0.026\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.025\n",
            "loss_avg: 0.025\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.020\n",
            "loss_avg: 0.020\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.021\n",
            "loss_avg: 0.021\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.025\n",
            "loss_avg: 0.025\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.023\n",
            "loss_avg: 0.023\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.020\n",
            "loss_avg: 0.020\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.026\n",
            "loss_avg: 0.026\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.019\n",
            "loss_avg: 0.019\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.024\n",
            "loss_avg: 0.024\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.016\n",
            "loss_avg: 0.016\n",
            "acc_avg: 0.997\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.026\n",
            "loss_avg: 0.026\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.024\n",
            "loss_avg: 0.024\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.067\n",
            "loss_avg: 0.067\n",
            "acc_avg: 0.976\n",
            "\n",
            "objective: 0.042\n",
            "loss_avg: 0.042\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.017\n",
            "loss_avg: 0.017\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.018\n",
            "loss_avg: 0.018\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.017\n",
            "loss_avg: 0.017\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.054\n",
            "loss_avg: 0.054\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.030\n",
            "loss_avg: 0.030\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.026\n",
            "loss_avg: 0.026\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.070\n",
            "loss_avg: 0.070\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.058\n",
            "loss_avg: 0.058\n",
            "acc_avg: 0.979\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.045\n",
            "loss_avg: 0.045\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.045\n",
            "loss_avg: 0.045\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.025\n",
            "loss_avg: 0.025\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.020\n",
            "loss_avg: 0.020\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.025\n",
            "loss_avg: 0.025\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.023\n",
            "loss_avg: 0.023\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.051\n",
            "loss_avg: 0.051\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.053\n",
            "loss_avg: 0.053\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.030\n",
            "loss_avg: 0.030\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.020\n",
            "loss_avg: 0.020\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.047\n",
            "loss_avg: 0.047\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.048\n",
            "loss_avg: 0.048\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.021\n",
            "loss_avg: 0.021\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.030\n",
            "loss_avg: 0.030\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.025\n",
            "loss_avg: 0.025\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.025\n",
            "loss_avg: 0.025\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.052\n",
            "loss_avg: 0.052\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.049\n",
            "loss_avg: 0.049\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.059\n",
            "loss_avg: 0.059\n",
            "acc_avg: 0.982\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.030\n",
            "loss_avg: 0.030\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.059\n",
            "loss_avg: 0.059\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.058\n",
            "loss_avg: 0.058\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.058\n",
            "loss_avg: 0.058\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.024\n",
            "loss_avg: 0.024\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.013\n",
            "loss_avg: 0.013\n",
            "acc_avg: 0.999\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.018\n",
            "loss_avg: 0.018\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.043\n",
            "loss_avg: 0.043\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.024\n",
            "loss_avg: 0.024\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.039\n",
            "loss_avg: 0.039\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.025\n",
            "loss_avg: 0.025\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.023\n",
            "loss_avg: 0.023\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.024\n",
            "loss_avg: 0.024\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.021\n",
            "loss_avg: 0.021\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.058\n",
            "loss_avg: 0.058\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.017\n",
            "loss_avg: 0.017\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.017\n",
            "loss_avg: 0.017\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.043\n",
            "loss_avg: 0.043\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.078\n",
            "loss_avg: 0.078\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.019\n",
            "loss_avg: 0.019\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.049\n",
            "loss_avg: 0.049\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.039\n",
            "loss_avg: 0.039\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.026\n",
            "loss_avg: 0.026\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.055\n",
            "loss_avg: 0.055\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.042\n",
            "loss_avg: 0.042\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.053\n",
            "loss_avg: 0.053\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.049\n",
            "loss_avg: 0.049\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.075\n",
            "loss_avg: 0.075\n",
            "acc_avg: 0.978\n",
            "\n",
            "objective: 0.042\n",
            "loss_avg: 0.042\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.024\n",
            "loss_avg: 0.024\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.060\n",
            "loss_avg: 0.060\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.050\n",
            "loss_avg: 0.050\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.060\n",
            "loss_avg: 0.060\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.042\n",
            "loss_avg: 0.042\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.049\n",
            "loss_avg: 0.049\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.006\n",
            "loss_avg: 0.006\n",
            "acc_avg: 1.000\n",
            "\n",
            "Epoch eval:\n",
            "Average acc: 0.990\n",
            "Recall macro: 0.776\n",
            "F1 macro: 0.793\n",
            "\n",
            "Validation (OOD/Trans):\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "objective: 1.892\n",
            "loss_avg: 1.892\n",
            "acc_avg: 0.623\n",
            "\n",
            "Epoch eval:\n",
            "Average acc: 0.623\n",
            "Recall macro: 0.387\n",
            "F1 macro: 0.368\n",
            "Validation F1-macro_all: 0.368\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\n",
            "Epoch [10]:\n",
            "\n",
            "Train:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "objective: 0.016\n",
            "loss_avg: 0.016\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.014\n",
            "loss_avg: 0.014\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.024\n",
            "loss_avg: 0.024\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.020\n",
            "loss_avg: 0.020\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.019\n",
            "loss_avg: 0.019\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.061\n",
            "loss_avg: 0.061\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.020\n",
            "loss_avg: 0.020\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.014\n",
            "loss_avg: 0.014\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.024\n",
            "loss_avg: 0.024\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.017\n",
            "loss_avg: 0.017\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.981\n",
            "\n",
            "objective: 0.012\n",
            "loss_avg: 0.012\n",
            "acc_avg: 0.998\n",
            "\n",
            "objective: 0.020\n",
            "loss_avg: 0.020\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.020\n",
            "loss_avg: 0.020\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.017\n",
            "loss_avg: 0.017\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.030\n",
            "loss_avg: 0.030\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.072\n",
            "loss_avg: 0.072\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.025\n",
            "loss_avg: 0.025\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.039\n",
            "loss_avg: 0.039\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.047\n",
            "loss_avg: 0.047\n",
            "acc_avg: 0.982\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.053\n",
            "loss_avg: 0.053\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.023\n",
            "loss_avg: 0.023\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.059\n",
            "loss_avg: 0.059\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.039\n",
            "loss_avg: 0.039\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.057\n",
            "loss_avg: 0.057\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.020\n",
            "loss_avg: 0.020\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.019\n",
            "loss_avg: 0.019\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.030\n",
            "loss_avg: 0.030\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.068\n",
            "loss_avg: 0.068\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.039\n",
            "loss_avg: 0.039\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.023\n",
            "loss_avg: 0.023\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.025\n",
            "loss_avg: 0.025\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.053\n",
            "loss_avg: 0.053\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.039\n",
            "loss_avg: 0.039\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.026\n",
            "loss_avg: 0.026\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.030\n",
            "loss_avg: 0.030\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.021\n",
            "loss_avg: 0.021\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.023\n",
            "loss_avg: 0.023\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.030\n",
            "loss_avg: 0.030\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.042\n",
            "loss_avg: 0.042\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.020\n",
            "loss_avg: 0.020\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.016\n",
            "loss_avg: 0.016\n",
            "acc_avg: 0.998\n",
            "\n",
            "objective: 0.019\n",
            "loss_avg: 0.019\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.026\n",
            "loss_avg: 0.026\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.051\n",
            "loss_avg: 0.051\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.052\n",
            "loss_avg: 0.052\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.026\n",
            "loss_avg: 0.026\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.043\n",
            "loss_avg: 0.043\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.045\n",
            "loss_avg: 0.045\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.050\n",
            "loss_avg: 0.050\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.020\n",
            "loss_avg: 0.020\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.024\n",
            "loss_avg: 0.024\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.056\n",
            "loss_avg: 0.056\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.052\n",
            "loss_avg: 0.052\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.050\n",
            "loss_avg: 0.050\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.048\n",
            "loss_avg: 0.048\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.021\n",
            "loss_avg: 0.021\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.017\n",
            "loss_avg: 0.017\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.023\n",
            "loss_avg: 0.023\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.011\n",
            "loss_avg: 0.011\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.045\n",
            "loss_avg: 0.045\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.039\n",
            "loss_avg: 0.039\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.063\n",
            "loss_avg: 0.063\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.048\n",
            "loss_avg: 0.048\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.017\n",
            "loss_avg: 0.017\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.062\n",
            "loss_avg: 0.062\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.025\n",
            "loss_avg: 0.025\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.043\n",
            "loss_avg: 0.043\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.050\n",
            "loss_avg: 0.050\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.042\n",
            "loss_avg: 0.042\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.995\n",
            "\n",
            "Epoch eval:\n",
            "Average acc: 0.990\n",
            "Recall macro: 0.816\n",
            "F1 macro: 0.827\n",
            "\n",
            "Validation (OOD/Trans):\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "objective: 2.039\n",
            "loss_avg: 2.039\n",
            "acc_avg: 0.597\n",
            "\n",
            "Epoch eval:\n",
            "Average acc: 0.597\n",
            "Recall macro: 0.367\n",
            "F1 macro: 0.332\n",
            "Validation F1-macro_all: 0.332\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\n",
            "Epoch [11]:\n",
            "\n",
            "Train:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.008\n",
            "loss_avg: 0.008\n",
            "acc_avg: 0.999\n",
            "\n",
            "objective: 0.016\n",
            "loss_avg: 0.016\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.018\n",
            "loss_avg: 0.018\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.024\n",
            "loss_avg: 0.024\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.015\n",
            "loss_avg: 0.015\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.015\n",
            "loss_avg: 0.015\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.018\n",
            "loss_avg: 0.018\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.049\n",
            "loss_avg: 0.049\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.056\n",
            "loss_avg: 0.056\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.026\n",
            "loss_avg: 0.026\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.025\n",
            "loss_avg: 0.025\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.063\n",
            "loss_avg: 0.063\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.015\n",
            "loss_avg: 0.015\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.020\n",
            "loss_avg: 0.020\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.033\n",
            "loss_avg: 0.033\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.011\n",
            "loss_avg: 0.011\n",
            "acc_avg: 0.999\n",
            "\n",
            "objective: 0.020\n",
            "loss_avg: 0.020\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.015\n",
            "loss_avg: 0.015\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.017\n",
            "loss_avg: 0.017\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.018\n",
            "loss_avg: 0.018\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.043\n",
            "loss_avg: 0.043\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.030\n",
            "loss_avg: 0.030\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.024\n",
            "loss_avg: 0.024\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.023\n",
            "loss_avg: 0.023\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.018\n",
            "loss_avg: 0.018\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.025\n",
            "loss_avg: 0.025\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.026\n",
            "loss_avg: 0.026\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.016\n",
            "loss_avg: 0.016\n",
            "acc_avg: 0.997\n",
            "\n",
            "objective: 0.039\n",
            "loss_avg: 0.039\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.055\n",
            "loss_avg: 0.055\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.023\n",
            "loss_avg: 0.023\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.052\n",
            "loss_avg: 0.052\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.052\n",
            "loss_avg: 0.052\n",
            "acc_avg: 0.980\n",
            "\n",
            "objective: 0.039\n",
            "loss_avg: 0.039\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.024\n",
            "loss_avg: 0.024\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.010\n",
            "loss_avg: 0.010\n",
            "acc_avg: 0.998\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.020\n",
            "loss_avg: 0.020\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.046\n",
            "loss_avg: 0.046\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.014\n",
            "loss_avg: 0.014\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.026\n",
            "loss_avg: 0.026\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.030\n",
            "loss_avg: 0.030\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.053\n",
            "loss_avg: 0.053\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.026\n",
            "loss_avg: 0.026\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.032\n",
            "loss_avg: 0.032\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.045\n",
            "loss_avg: 0.045\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.018\n",
            "loss_avg: 0.018\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.042\n",
            "loss_avg: 0.042\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.042\n",
            "loss_avg: 0.042\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.051\n",
            "loss_avg: 0.051\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.043\n",
            "loss_avg: 0.043\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.025\n",
            "loss_avg: 0.025\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.984\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.019\n",
            "loss_avg: 0.019\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.019\n",
            "loss_avg: 0.019\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.026\n",
            "loss_avg: 0.026\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.044\n",
            "loss_avg: 0.044\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.045\n",
            "loss_avg: 0.045\n",
            "acc_avg: 0.987\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.023\n",
            "loss_avg: 0.023\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.030\n",
            "loss_avg: 0.030\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.030\n",
            "loss_avg: 0.030\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.020\n",
            "loss_avg: 0.020\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.024\n",
            "loss_avg: 0.024\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.038\n",
            "loss_avg: 0.038\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.042\n",
            "loss_avg: 0.042\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.037\n",
            "loss_avg: 0.037\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.020\n",
            "loss_avg: 0.020\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.045\n",
            "loss_avg: 0.045\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.051\n",
            "loss_avg: 0.051\n",
            "acc_avg: 0.985\n",
            "\n",
            "objective: 0.034\n",
            "loss_avg: 0.034\n",
            "acc_avg: 0.990\n",
            "\n",
            "objective: 0.040\n",
            "loss_avg: 0.040\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.024\n",
            "loss_avg: 0.024\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.015\n",
            "loss_avg: 0.015\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.036\n",
            "loss_avg: 0.036\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.050\n",
            "loss_avg: 0.050\n",
            "acc_avg: 0.983\n",
            "\n",
            "objective: 0.017\n",
            "loss_avg: 0.017\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.015\n",
            "loss_avg: 0.015\n",
            "acc_avg: 0.998\n",
            "\n",
            "objective: 0.021\n",
            "loss_avg: 0.021\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.024\n",
            "loss_avg: 0.024\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.019\n",
            "loss_avg: 0.019\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.021\n",
            "loss_avg: 0.021\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.030\n",
            "loss_avg: 0.030\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.024\n",
            "loss_avg: 0.024\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.022\n",
            "loss_avg: 0.022\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.027\n",
            "loss_avg: 0.027\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.028\n",
            "loss_avg: 0.028\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.035\n",
            "loss_avg: 0.035\n",
            "acc_avg: 0.989\n",
            "\n",
            "objective: 0.031\n",
            "loss_avg: 0.031\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.020\n",
            "loss_avg: 0.020\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.026\n",
            "loss_avg: 0.026\n",
            "acc_avg: 0.995\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.030\n",
            "loss_avg: 0.030\n",
            "acc_avg: 0.993\n",
            "\n",
            "objective: 0.030\n",
            "loss_avg: 0.030\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.041\n",
            "loss_avg: 0.041\n",
            "acc_avg: 0.986\n",
            "\n",
            "objective: 0.029\n",
            "loss_avg: 0.029\n",
            "acc_avg: 0.991\n",
            "\n",
            "objective: 0.019\n",
            "loss_avg: 0.019\n",
            "acc_avg: 0.996\n",
            "\n",
            "objective: 0.020\n",
            "loss_avg: 0.020\n",
            "acc_avg: 0.994\n",
            "\n",
            "objective: 0.025\n",
            "loss_avg: 0.025\n",
            "acc_avg: 0.992\n",
            "\n",
            "objective: 0.048\n",
            "loss_avg: 0.048\n",
            "acc_avg: 0.988\n",
            "\n",
            "objective: 0.062\n",
            "loss_avg: 0.062\n",
            "acc_avg: 0.986\n",
            "\n",
            "Epoch eval:\n",
            "Average acc: 0.991\n",
            "Recall macro: 0.830\n",
            "F1 macro: 0.848\n",
            "\n",
            "Validation (OOD/Trans):\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "objective: 2.071\n",
            "loss_avg: 2.071\n",
            "acc_avg: 0.604\n",
            "\n",
            "Epoch eval:\n",
            "Average acc: 0.604\n",
            "Recall macro: 0.344\n",
            "F1 macro: 0.341\n",
            "Validation F1-macro_all: 0.341\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fVS-X02iL8Kc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "IFT6759.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMn0tbT19aBTMd/lEGMQ0hS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}